{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "help.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsWjQ2Ts-C1_",
        "colab_type": "code",
        "outputId": "46736f8c-fc1a-4cb5-da1b-e4d8f171b66a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJt5CBKp-VMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.utils import shuffle\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0v8hR2v-WwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import the csv\n",
        "data = pd.read_csv('helpdesk.csv')\n",
        "# np.sum(data.isna())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqNKCf-900Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to make the caseID start from zero\n",
        "# data['CaseID'] = data['CaseID'] - 173688 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjGyYOcV-xFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#given the caseID, array 'numarray' outputs the number of events in  that particular caseID trace.\n",
        "caseS = pd.Series(data['CaseID'] )\n",
        "numarray = caseS.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWBzAd2ojS_M",
        "colab_type": "code",
        "outputId": "3cec9969-ad12-4908-ee01-1d3fb23616c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# outputs the number of traces where the number of events in the particular trace is the index of below Series(CaseID).\n",
        "numcaseID = pd.value_counts(data['CaseID']).value_counts()\n",
        "maxlen = max(numcaseID.index)\n",
        "maxlen"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QJoB2XnAXf7",
        "colab_type": "code",
        "outputId": "4e973360-f0f8-4642-e005-83eb53bff540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "actS = pd.Series(data['ActivityID'] )\n",
        "actS.value_counts()\n",
        "classes = actS.max()\n",
        "#zero will be for end of trace\n",
        "print(\"number of classes(zero not included which will be denoted later as end of trace) :\" +str(classes))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of classes(zero not included which will be denoted later as end of trace) :9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii9SlkL54mJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting it into datetime datatype of pandas for easy access of date, time and other operations.\n",
        "data['datetime'] = pd.to_datetime(data['CompleteTimestamp'])\n",
        "data.drop(['CompleteTimestamp'], axis=1, inplace=True)\n",
        "# data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LqZRI5hMKdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set finds the unique numbers in caseID i.e list all the unique caseIDs.\n",
        "ca_uni = list(set(data['CaseID'].values))\n",
        "# len(ca_uni)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW-eRF9z-iLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#datetime is shifted to find elapsed or concerned type of time further down the line.\n",
        "data['dapa'] = data['datetime'].shift(1)\n",
        "# data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mYp_jqwVlkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#difference of datetime is timedelta type in pandas which has a function called .total_seconds()\n",
        "data['elapsed'] = data['datetime'] - data['dapa']\n",
        "elapsec = [x.total_seconds() for x in data['elapsed'] ]\n",
        "data['elap'] = elapsec\n",
        "data.drop(columns=['elapsed','dapa'],inplace = True)\n",
        "# data.head(50)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fc51bd-GT1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#case at all times denote the index of data panda, and ca_uni contains unique caseIDs, we increment case with a[i] amount i.e the number of events in that particular trace denoted by i (element of ca_uni).\n",
        "case = 0\n",
        "for i in ca_uni:\n",
        "  data.loc[case,'elap'] = 0\n",
        "  case += numarray[ i ]\n",
        "  \n",
        "# data.head(10)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR9I43fq006x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converted the seconds into days\n",
        "lis = [(x.hour*3600 + x.minute*60 + x.second) for x in data['datetime']]\n",
        "data['from_midnight']  =lis\n",
        "# data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcIIduH41rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we notice by below graphs that most stuff happened during the evening/night\n",
        "# data['from_midnight'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0jFVpve6DN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we find the from_midnight and from_sun attributes using .weekday function of datetime object and converted everything into time(days) scale.\n",
        "li = [x.weekday()*86400 for x in data['datetime']]\n",
        "data['from_sun'] = li\n",
        "data['from_sun'] = (data['from_sun'] +  data['from_midnight'])/86400\n",
        "data['from_midnight'] = (data['from_midnight'])/86400\n",
        "data['elap'] = (data['elap'])/86400\n",
        "# data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrJCH2fqAfhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we see that no event occurred on Sunday and least events happenned on Tuesday most on Monday.\n",
        "#data['from_sun'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb6mSz008jYc",
        "colab_type": "code",
        "outputId": "7a98f258-1220-48df-ef25-9bf80c987f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"Below is the compilation of information of all the data we conjured.\")\n",
        "print(data.describe())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Below is the compilation of information of all the data we conjured.\n",
            "             CaseID    ActivityID          elap  from_midnight      from_sun\n",
            "count  13710.000000  13710.000000  13710.000000   13710.000000  13710.000000\n",
            "mean    2307.827279      5.284391      2.441152       0.729836      2.814446\n",
            "std     1318.502223      3.008803      5.821179       0.267444      1.404757\n",
            "min        2.000000      1.000000      0.000000       0.000035      0.623229\n",
            "25%     1168.000000      1.000000      0.000000       0.694540      1.733941\n",
            "50%     2304.000000      6.000000      0.004942       0.782818      2.819311\n",
            "75%     3456.750000      8.000000      1.284042       0.901840      3.934436\n",
            "max     4580.000000      9.000000     50.129676       0.999919      6.012118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0ZmzTHU87fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LtwO-goVx21",
        "colab_type": "code",
        "outputId": "a0c72794-9f06-4e26-e1b3-da646d2244ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# data.head(10)\n",
        "data.describe()\n",
        "# we see below if any null values are there, the results were zero in all the columns\n",
        "np.sum(data.isna())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CaseID           0\n",
              "ActivityID       0\n",
              "datetime         0\n",
              "elap             0\n",
              "from_midnight    0\n",
              "from_sun         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNYWt7APuAwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gcid denotes the group number categorized according to the caseID or the trace number.\n",
        "gcid = data.groupby('CaseID')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCBIC4puX8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#categorizing the data by individual traces\n",
        "act = []#contains all the events of a particular trace as one element.\n",
        "time = []#contains timestamp of all events of a particular trace as one element\n",
        "ofea = []#contains ofea(other features) like elapsed time, time from midnight, time from last sunday of all traces as one element\n",
        "for cid in ca_uni:\n",
        "  temp = gcid.get_group(cid)\n",
        "  act.append(temp['ActivityID'].values)\n",
        "  time.append(temp['datetime'].values)\n",
        "  ofea.append(temp[['elap','from_midnight','from_sun']].values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VFSd_5uvqa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padding the above arrays with the maximum number of events possible in our dataset which is 13 i.e maximum of 13 element was found in a trace\n",
        "padded_act = pad_sequences(act, padding = \"post\", maxlen = maxlen)\n",
        "padded_time = pad_sequences(time, padding = \"post\", maxlen = maxlen, dtype = 'datetime64[ns]')\n",
        "padded_ofea = pad_sequences(ofea, padding = \"post\", maxlen = maxlen, dtype = 'float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUkp8MeXyL_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding one-hot encoding of the padded activity for each concatenation and access later.\n",
        "X = to_categorical(\n",
        "    padded_act,\n",
        "    num_classes= classes+1,\n",
        "    dtype = 'int'\n",
        ")\n",
        "# X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNMmYW0Cz0HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatinating other features into the one-hot encoding making the shape(-1,13,10) for this dataset.\n",
        "X = np.concatenate((X,padded_ofea) , axis = 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtlM5-0z_ICc",
        "colab_type": "text"
      },
      "source": [
        "**PREFIX = decide here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItFt3y9GSgyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padded_time.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG0Uv0Vq_NBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#decide the length of prefix here\n",
        "prefix = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mbTpHU3md9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We remove all the traces where the end of trace has already occurerred as they would make our model bias if taken \n",
        "X_train = X[X[:,prefix-1,0] == 0]\n",
        "time = padded_time[X[:,prefix-1,0] == 0]\n",
        "# we also keep the corresponding timestamps in time array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wDEZziRou30",
        "colab_type": "code",
        "outputId": "68bee3b7-5e49-4344-92e6-10b4d6fca92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The shape of the data before cutting it for training and validation: \"+str(X_train.shape))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the data before cutting it for training and validation: (3803, 14, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-MX-zR27LbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train[:,:prefix,:].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F1oz3X48uAW",
        "colab_type": "code",
        "outputId": "47c346cb-c6ba-4324-f3a8-512a1e8511a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#For our purposes we take 80% of data for training and rest for testing results.  \n",
        "till = int(X_train.shape[0] *0.8)\n",
        "X_test = X_train[till:]\n",
        "X_train = X_train[:till]\n",
        "# X_test.shape\n",
        "print(\"The shape of the training data \"+str(X_train.shape))\n",
        "print(\"The shape of the testing data \"+str(X_test.shape))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the training data (3042, 14, 13)\n",
            "The shape of the testing data (761, 14, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx0ofcOOS5_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we do this for time array previously formed as well\n",
        "time_test = time[till:]\n",
        "time_train = time[:till]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CejemtJ0im_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epoch = 50\n",
        "batch_size = 16#since number of traces are small, we take small batch_size\n",
        "hidden_units = 100\n",
        "num_features = 13\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJmPkwGyBLW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PlotLosses(keras.callbacks.Callback):\n",
        "  \n",
        "    '''class to implement callback in keras\n",
        "    it would graph the losses as the model trains'''\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        \n",
        "        self.fig = plt.figure()\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.xlabel('epochs')\n",
        "        plt.ylabel('loss in MAE')\n",
        "        plt.legend()\n",
        "        plt.show();\n",
        "        \n",
        "plot = PlotLosses()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSY1lqqFCAzp",
        "colab_type": "text"
      },
      "source": [
        "**activity prediciton**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKIEUhBOh5AZ",
        "colab_type": "code",
        "outputId": "aede8c08-c027-4ce5-b3e9-85d543dbee64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "#model is separate model for only activity prediction hence no shared layer\n",
        "model1 = Sequential()\n",
        "model1.add(LSTM(hidden_units, input_shape = (prefix,num_features),return_sequences=True))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(LSTM( 100))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(classes+1,activation='softmax'))\n",
        "\n",
        "print(model1.summary())\n",
        "model1.compile(loss = 'mean_squared_error', optimizer='adam',metrics = ['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0703 22:19:10.237013 139885454280576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0703 22:19:10.257096 139885454280576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0703 22:19:10.259983 139885454280576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0703 22:19:10.488606 139885454280576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0703 22:19:10.499322 139885454280576 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0703 22:19:10.853984 139885454280576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 2, 100)            45600     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 127,410\n",
            "Trainable params: 127,210\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3C3Hkbcif5O",
        "colab_type": "code",
        "outputId": "a9f244a7-1dbe-4d23-efd9-23f0fbaedc2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "history = model1.fit(X_train[:,:prefix,:], X_train[:,prefix,:10], epochs=15, batch_size=batch_size,validation_split=0.2,callbacks=[plot]\n",
        "          ,verbose=0)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b9d1335c130c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model1.fit(X_train[:,:prefix,:], X_train[:,prefix,:10], epochs=15, batch_size=batch_size,validation_split=0.2,callbacks=[plot]\n\u001b[0;32m----> 2\u001b[0;31m           ,verbose=0)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-b8365b076e6f>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss in MAE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlotLosses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mshow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2075\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2076\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             _png.write_png(renderer._renderer, fh,\n\u001b[0;32m--> 523\u001b[0;31m                             self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAmIkhVCi-ik",
        "colab_type": "code",
        "outputId": "fb70f6b1-8f80-4ba8-8c83-0ae0dec1a7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accr = model1.evaluate(X_test[:,:prefix,:],X_test[:,prefix,:10])\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761/761 [==============================] - 0s 80us/step\n",
            "Test set\n",
            "  Loss: 0.036\n",
            "  Accuracy: 0.779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGKDaQP3B8jg",
        "colab_type": "text"
      },
      "source": [
        "**Time prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOytmtG20fWB",
        "colab_type": "code",
        "outputId": "a9f567cf-ab50-4513-e1b1-6dc0cf05ab42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#model2 calcualtes time only hence no shared layer\n",
        "model2 = Sequential()\n",
        "model2.add(LSTM(hidden_units,input_shape = (prefix,num_features),return_sequences=True))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(LSTM(100 ))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(128,activation='relu'))\n",
        "\n",
        "model2.add(Dense(32,activation='relu'))\n",
        "model2.add(Dense(1,activation='linear'))\n",
        "\n",
        "print(model2.summary())\n",
        "model2.compile(loss = 'mean_squared_error', optimizer='adam',metrics = ['mae'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 2, 100)            45600     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 143,489\n",
            "Trainable params: 143,289\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1WRkpzq0_Ok",
        "colab_type": "code",
        "outputId": "69c5a72d-c89d-4bbe-bddf-87d94547ce87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "history = model2.fit(X_train[:,:prefix,:], X_train[:,prefix,10], epochs=50, batch_size=batch_size,validation_split=0.2,callbacks=[plot]\n",
        "          ,verbose=0)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-5d686db1805c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model2.fit(X_train[:,:prefix,:], X_train[:,prefix,10], epochs=50, batch_size=batch_size,validation_split=0.2,callbacks=[plot]\n\u001b[0;32m----> 2\u001b[0;31m           ,verbose=0)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo2eynMA3JJ3",
        "colab_type": "code",
        "outputId": "6d846d2f-76ed-439e-8749-4bbeb79be793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accr = model2.evaluate(X_test[:,:prefix,:],X_test[:,prefix,10])\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  MAE: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761/761 [==============================] - 0s 85us/step\n",
            "Test set\n",
            "  Loss: 39.818\n",
            "  MAE: 3.493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6rePtZ8CHje",
        "colab_type": "text"
      },
      "source": [
        "**shared layer of activity and time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehhSPji2ywXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import *    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_kMcfPEcCPq",
        "colab_type": "code",
        "outputId": "0ef8a053-97fb-46b5-f9ec-95f8ff9c47be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "#shared model where first layer is common then two layers branch out specializing in activity and time prediction respectively\n",
        "inp = Input((prefix,num_features),name='inp')  \n",
        "\n",
        "x = LSTM(hidden_units,input_shape = (prefix,num_features),return_sequences=True)(inp)\n",
        "x = Dropout(0.6)(x)\n",
        "temp1 =LSTM(100 )(x)\n",
        "temp = LSTM(100)(x)\n",
        "\n",
        "temp = BatchNormalization()(temp)\n",
        "temp = Activation('relu')(temp)\n",
        "temp= Dropout(0.6)(temp)\n",
        "temp1= Dropout(0.6)(temp1)\n",
        "temp = Dense(128,activation='relu')(temp)\n",
        "temp = BatchNormalization()(temp)\n",
        "temp = Activation('relu')(temp)\n",
        "temp= Dropout(0.6)(temp)\n",
        "\n",
        "act_output = Dense(classes+1, activation='softmax', kernel_initializer='glorot_uniform', name='act_output')(temp1)\n",
        "time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(temp)\n",
        "\n",
        "\n",
        "model3 = Model(inputs=[inp], outputs=[act_output, time_output])\n",
        "print(model3.summary())\n",
        "model3.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mean_squared_error'}, optimizer='Adam',metrics = {'act_output':'accuracy', 'time_output':'mae'})\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0703 22:20:56.859849 139885454280576 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0703 22:20:57.358434 139885454280576 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0703 22:20:57.379073 139885454280576 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0703 22:20:57.490425 139885454280576 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inp (InputLayer)                (None, 2, 13)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 2, 100)       45600       inp[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 2, 100)       0           lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 100)          80400       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 100)          400         lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 100)          0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 100)          0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 128)          12928       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128)          512         dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 100)          80400       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128)          0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100)          0           lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 128)          0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "act_output (Dense)              (None, 10)           1010        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_output (Dense)             (None, 1)            129         dropout_8[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 221,379\n",
            "Trainable params: 220,923\n",
            "Non-trainable params: 456\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLYIzf-4cSF4",
        "colab_type": "code",
        "outputId": "3d33461d-c872-4106-fa71-b2ce98d63be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "history = model3.fit(X_train[:,:prefix,:], {'act_output':X_train[:,prefix,:10], 'time_output':X_train[:,prefix,10]}, epochs=50, batch_size=batch_size,validation_split=0.2,callbacks=[plot]\n",
        "          ,verbose=0)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYFPW97/H3t3sGRhj2VR0VUAMK\nI+gZTaJBDd5oArhFPbg+7mY7akyOUaNP4slNbnLjvTfe3OMNekxOxGCUazQmbtlciCcJOiAIiKLB\n5YALA4KCMDh0f+8fVUMv09PdM0x1M1Of1/P0Qy2/qvp2TVOfrqWrzN0REZH4SlS7ABERqS4FgYhI\nzCkIRERiTkEgIhJzCgIRkZhTEIiIxFzkQWBmSTN73sweDvtPMLMlZrbUzJ4xs4OirkFERDpXiT2C\nq4FVWf0/Ac5z92nAPcBNFahBREQ6EWkQmFkDMAu4M2uwA4PD7iHAW1HWICIixdVEPP9bgW8Ag7KG\nXQY8ambbgQ+AT5SayciRI33cuHGRFCgi0lctXrx4g7uPKtUusiAws9nAendfbGbHZ426Bpjp7ovM\n7FrgfxGEQ/70VwBXAOy///40NzdHVaqISJ9kZm+U0y7KQ0PHAKeY2evAvcAMM3sEmOrui8I29wFH\nF5rY3e9w9yZ3bxo1qmSgiYhIN0UWBO5+g7s3uPs44GzgCeBUYIiZfSxs9hlyTySLiEiFRX2OIIe7\n7zSzy4FfmVka2ARcUskaREQkV0WCwN2fAp4Kux8EHqzEckVEpDT9slhEJOYUBCIiMacgEBGJuYqe\nLK64ZffCto0wZjKMmQIDR1a7IhGRPU7fDoKVD8LqxzP99WPDUAiDYcxkGPkxqOlXvRpFRKqsbwfB\nuffB1vXw7sqs1wpYNBdSHwVtEjUwcmLHgBg0FsyqW7+ISAX07SAAqB8dvA78dGZYaidsfDUIhfaA\neOMvsHxBps1ew3ODYcxkGDUJ+g2o/HsQEYlQ3w+CQpI1MHpS8Go8MzN8+yZ498XMnsO7K2HJXdC2\nLRhvCRh+YMeAGLq/9h5EpNeKZxB0Zq9hMO6Y4NUunYZNr+UeWnp7Gbz460ybfoOyDi2FITH6EKgb\n3HEZIiJ7GAVBKYkEjDgweB16Smb4jq2wflXu4aXl90PzTzNthh6Qu+cwZgoMHw+JZOXfh4hIJxQE\n3dW/HvY7Mni1c4f31+YeWnp3Jax+DDwdtKnZK9hbyD+8NGB4dd6HiMSegqAnmcHQ/YLXxM9mhrdt\nh5aXcw8vvfwoPH93ps2gfQpc2nowJGsr/z5EJFYUBJVQuxfsMy14tXMPL21dkXt565qnIN0WtEnU\nBlcq5Z9/qB+tk9Mi0mMUBNViBoPGBK+DTsgMT7XBhldyDy+9thBeuDfTZsDIwpe21tZV/n2ISK+n\nINjTJGthzKHBi7Myw7e9l3to6d2V0Pwz2Lk9GG9JGHFQx8NLQxq09yAiRSkIeosBw2H89ODVLp2C\n917LPby0bjGsfCDTpv+Qwpe29q+v/HsQkT2SgqA3SyRh5EHBa/JpmeGtH3S8tHXZvfDRlkybYeM7\nHl4aNj64XFZEYkVB0BfVDYb9Px682rnD5jfzDi+tgJceATxoUzsARh+aFxCHBj+0E5E+S0EQF2Yw\n7IDgNWlmZvhH26BlVe6tNVb9Jri1RrvBDR0PL404KLhVh4j0jNTO4DY32zYEt8//cEPQfdgc6D8o\n0kXrf3Lc9RsA+/5D8GrnDlveyew1tO9F/P1PkN4ZtEn2h1ETO/5yun5Udd6HyJ7mow+zNujvBRv1\nD8ON/LZwWPvGfttG2L6ZXXvn2fY/Orx4JDoKAunIDAbvHbwO/kxm+M4dsGF17pVLf/8TLLsn02bg\n6I5XLo2aCDX9K/8+RHpKOh1+W9/Y8Rv7rg16OO7DjUF3+xV9+RI1wSXgA0bAwBEwtjHoHxgOa3+1\n9w+M/suVgkDKV9M/+NCObcwdvrUF1uc98+HZf4PUjmC8JYMHAOUHxOB9dGmrVEdba94GvcQ39u2b\nMreJyddvULBBHzAiePjV6MmZ/kIb+Lohe9znXkEgu69+FNQfDxOOzwxL7YT3/p57aOk/F8GK+zNt\n6oZ2PLQ0ehL0G1jhNyC9mju0bs58E8/ZwG/M6w438B9tLTwvS2RttEcGn8f27uxv6e3dew3vEz/k\nVBBINJI1wSGhURNhyhmZ4ds3w/q8Zz48/wto+zBsYDB8QoFnPhygS1vjYudHBTbo+d/Y8zbwnio8\nr9oB4UZ8eLDhHvmxzCGZQhv4uqGx/JwpCKSy9hoKBxwdvNql07D59Y6Xtq76LbtOnvWrz7q0tT0k\nDg12s2XP5Q47tuQeOy/6jX0j7Pigk5lZcClz+0Z7+ARoODLsH1l4A68nCpbF3Aucpd7DNDU1eXNz\nc7XLkErbsRVaXsq7Md8KaH0/02bI/gUubT1Qz3yISmonbM+72iX7G3v+Rn3bxszzwfMl+3c81LLr\nuHqBb+x7DdPftYvMbLG7N5Vqpz0C2XP1r4eGpuDVzh0+WNfxmQ+v/D5zeKCmLrxra975h4EjqvM+\n9lTumUscO/3GnndIpnVz5/OrG5LZcA/dH/Y5vPgGvt/APe6kaVwpCKR3MQtupDekAT52UmZ4Wyts\nyHvmw+rHYekvMm3qxxZ45sPHoKZf5d9HFNKpzCWOOd/YixyS2dlaeF6J2qyN+HDYe2rnlze2H4PX\nszN6LQWB9A21dcHGau+pucM7PPNhBSz6c+ZwRaIGRk7MDYixU6B+TPW/rbZtL3x9emff2LdvouAP\nkgD6Dw421gNGwqC9w2vXh+dd3ph1UrX/4Oq/f6kYBYH0bfWjoX4GHDgjMyzVBhtfzT289MZ/wPIF\nmTYDRgTBMDrr/MPoQ4KHDHVHOh0cVil0OWOHDXzY3bat8LwsmbsRH31I55c3tnfrB31ShIJA4idZ\nG2w8Rx8CjWdmhm97r+OlrYt/nvXMhwQMP7Djj+J2/eK02CGZ94pc4jgw94qXkRMzh2RyNvDhsJhe\n4ijRURCItBswHMZ9Kni1S6dg0+u5h5feXgov/rqTmVi4AQ8PtYw4MLgLbM4GPe+QTHf3MkR6iIJA\npJhEMtiYjzgQDj01M3zHluCZD1veyT0Mo0scpRdSEIh0R/9BsN9R1a5CpEfoQKOISMwpCEREYk5B\nICIScwoCEZGYizwIzCxpZs+b2cNhv5nZ98xstZmtMrOroq5BREQ6V4mrhq4GVgGDw/6LgP2ASe6e\nNrPRFahBREQ6EekegZk1ALOAO7MGfwn4jnvw3Dd3Xx9lDSIiUlzUh4ZuBb4BZD/s80Bgjpk1m9lj\nZnZwoQnN7IqwTXNLS0vEZYqIxFdkQWBms4H17r44b1R/oDV8WMK/AT8rNL273+HuTe7eNGrUqKjK\nFBGJvSjPERwDnGJmM4E6YLCZ/QJYCzwQtnkQ+PcIaxARkRIi2yNw9xvcvcHdxwFnA0+4+/nAr4FP\nh82OA1ZHVYOIiJRWjXsN/QCYb2bXAFuBy6pQg4iIhCoSBO7+FPBU2L2Z4EoiERHZA+iXxSIiMacg\nEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERi\nTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCI\niMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSAiEnPdCgIzq+npQkREpDo6DQIzeyar++68\n0c9GVpGIiFRUsT2CgVndk/PGWQS1iIhIFRQLAu/mOBER6UWKHesfamanE4TFUDP7fDjcgCGRVyYi\nIhVRLAieBk7J6j45a9zCyCoSEZGK6jQI3P3izsaZ2ZhoyhERkUor+/JRMxtqZpea2Z+A5yOsSURE\nKqhoEJjZXmZ2tpn9BlgO/E/gvwIN5S7AzJJm9ryZPZw3/MdmtrU7RYuISM8p9juCe4DVwGeA/wOM\nAza5+1Punu7CMq4GVuXNuwkY1uVqRUSkxxU7WXwosIlgI77K3VNm1qXLRs2sAZgFfA/4WjgsCdwC\nnAuc3p2iRaTva2trY+3atbS2tla7lD1eXV0dDQ0N1NbWdmv6YieLp5nZJOAc4I9mtgEYZGZj3P3d\nMud/K/ANYFDWsH8CfuPub5vpd2kiUtjatWsZNGgQ48aNQ9uKzrk7GzduZO3atYwfP75b8yh6jsDd\nX3L3b7v7JIJDPPOA58zsL6VmbGazgfXuvjhr2D7AWQSHmkpNf4WZNZtZc0tLS6nmItLHtLa2MmLE\nCIVACWbGiBEjdmvPqeybx4Ub9MVm9s/A9DImOQY4xcxmAnXAYGAlsAN4NfzjDjCzV939oALLuwO4\nA6CpqUm/ZBaJIYVAeXZ3PXUaBGb24xLTFv1RmbvfANwQzut44J/dfXbeMrYWCgERkT1BfX09W7f2\n/Ysbi+0RfBFYASwA3kI3mhMR6ZOKnSPYm+DQzEnABUAt8JC73+Xud3VlIeElp7MLDK/vynxERKrB\n3bn22muZMmUKjY2N3HfffQC8/fbbHHvssUybNo0pU6bw5z//mVQqxUUXXbSr7Y9+9KMqV19asauG\nNgJzgbnhZaBnAy+a2XXunv98AhGRPuuBBx5g6dKlLFu2jA0bNnDkkUdy7LHHcs8993DSSSdx4403\nkkql2LZtG0uXLmXdunWsWLECgM2bN1e5+tJKniw2syMILiH9DPAYsLj4FCIiPetffruSF9/6oEfn\neeg+g/n2yfmPWinsmWee4ZxzziGZTDJmzBiOO+44nnvuOY488kguueQS2traOO2005g2bRoTJkxg\nzZo1XHnllcyaNYsTTzyxR+uOQrFfFn/HzBYT/BDsaaDJ3S919xcrVp2IyB7s2GOPZeHChey7775c\ndNFFzJs3j2HDhrFs2TKOP/545s6dy2WXXVbtMksqtkdwE/AaMDV8/bfwEiUD3N0Pi748ERHK/uYe\nlenTp3P77bdz4YUX8t5777Fw4UJuueUW3njjDRoaGrj88svZsWMHS5YsYebMmfTr148zzjiDiRMn\ncv7551e19nIUC4Lu/URNRKSPOf300/nrX//K1KlTMTN++MMfMnbsWO666y5uueUWamtrqa+vZ968\neaxbt46LL76YdDq4Jdv3v//9Kldfmrnv+b/Vampq8ubm5mqXISIVtGrVKg455JBql9FrFFpfZrbY\n3ZtKTVv28whERKRvUhCIiMScgkBEJObK+R3BMcDNwAFh+/arhiZEW5qIiFRCOXcf/SlwDcEPyVLR\nliMiIpVWThC87+6PRV6JiIhURTlB8KSZ3QI8QPAsAQDcfUlkVYmISMWUEwQfD//NvhbVgRk9X46I\nSO9V7PkFr7/+OrNnz951M7o9SckgcPdPV6IQERGpjmI3nTs//PdrhV6VK1FEpDquv/56brvttl39\nN998M9/97nc54YQTOOKII2hsbOShhx7q8nxbW1u5+OKLaWxs5PDDD+fJJ58EYOXKlRx11FFMmzaN\nww47jFdeeYUPP/yQWbNmMXXqVKZMmbLrWQg9qdgewcDw30E9vlQRka547Hp4Z3nPznNsI3zuB0Wb\nzJkzh69+9at85StfAWDBggX87ne/46qrrmLw4MFs2LCBT3ziE5xyyildem7wbbfdhpmxfPlyXnrp\nJU488URWr17N3LlzufrqqznvvPP46KOPSKVSPProo+yzzz488sgjALz//vvdf8+dKPZgmtvDf/+l\nx5cqItILHH744axfv5633nqLlpYWhg0bxtixY7nmmmtYuHAhiUSCdevW8e677zJ27Niy5/vMM89w\n5ZVXAjBp0iQOOOAAVq9ezSc/+Um+973vsXbtWj7/+c9z8MEH09jYyNe//nWuu+46Zs+ezfTp03v8\nfZZzslhEpLpKfHOP0llnncX999/PO++8w5w5c5g/fz4tLS0sXryY2tpaxo0bR2tra48s69xzz+Xj\nH/84jzzyCDNnzuT2229nxowZLFmyhEcffZSbbrqJE044gW9961s9srx2CgIRkSLmzJnD5ZdfzoYN\nG3j66adZsGABo0ePpra2lieffJI33nijy/OcPn068+fPZ8aMGaxevZo333yTiRMnsmbNGiZMmMBV\nV13Fm2++yQsvvMCkSZMYPnw4559/PkOHDuXOO+/s8feoIBARKWLy5Mls2bKFfffdl7333pvzzjuP\nk08+mcbGRpqampg0aVKX5/nlL3+ZL33pSzQ2NlJTU8PPf/5z+vfvz4IFC7j77rupra1l7NixfPOb\n3+S5557j2muvJZFIUFtby09+8pMef48ln0dgZlcD/w5sAe4EDgeud/ff93g1ndDzCETiR88j6Jqo\nn0dwibt/AJwIDAMuAKp3wE5ERHpUOYeG2q+Jmgnc7e4rrSvXSYmIxMjy5cu54IILcob179+fRYsW\nVami0soJgsVm9nuCZxjfYGaDgHS0ZYmI9E6NjY0sXbq02mV0STlBcCkwDVjj7tvMbDhwcbRliYiA\nu3fph1pxtbvPni/nHMEngZfdfXN424mbgJ7/aZuISJa6ujo2bty42xu5vs7d2bhxI3V1dd2eRzl7\nBD8BpprZVODrBFcOzQOO6/ZSRURKaGhoYO3atbS0tFS7lD1eXV0dDQ0N3Z6+nCDY6e5uZqcC/+ru\nPzWzS7u9RBGRMtTW1jJ+/PhqlxEL5QTBFjO7geCy0elmlgBqoy1LREQqpZxzBHMInkx2ibu/AzQA\nt0RalYiIVEzJIAg3/vOBIWY2G2h193mRVyYiIhVRMgjM7B+BZ4GzgH8EFpnZmVEXJiIilVHOOYIb\ngSPdfT2AmY0C/gjcH2VhIiJSGeWcI0i0h0BoY5nTiYhIL1DOHsHjZvY74Jdh/xzg0ehKEhGRSioZ\nBO5+rZmdARwTDrrD3R+MtiwREamUsh5M4+6/An4VcS0iIlIFnQaBmW0BCt3kwwB398HlLMDMkkAz\nsM7dZ5vZfKAJaCO4GukL7t7W5cpFRKRHdHrS190HufvgAq9B5YZA6GpgVVb/fGAS0AjsBVzWrcpF\nRKRHRHr1j5k1ALMIblQHgLs/6iGCPYLu3ylJRER2W9SXgd4KfIMCD7Ixs1qC+xc9XmhCM7vCzJrN\nrFl3HxQRiU5kQRDejmK9uy/upMn/BRa6+58LjXT3O9y9yd2bRo0aFVWZIiKxV9ZVQ910DHCKmc0E\n6oDBZvYLdz/fzL4NjAK+EOHyRUSkDJHtEbj7De7e4O7jgLOBJ8IQuAw4CTjH3fXsYxGRKqvGrSLm\nAmOAv5rZUjP7VhVqEBGRUJSHhnZx96eAp8LuiixTRETKo5vHiYjEnIJARCTmFAQiIjGnIBARiTkF\ngYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIS\ncwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJA\nRCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5\nBYGISMxFHgRmljSz583s4bB/vJktMrNXzew+M+sXdQ0iItK5SuwRXA2syur/78CP3P0gYBNwaQVq\nEBGRTkQaBGbWAMwC7gz7DZgB3B82uQs4LcoaRESkuKj3CG4FvgGkw/4RwGZ33xn2rwX2jbgGEREp\nIrIgMLPZwHp3X9zN6a8ws2Yza25paenh6kREpF2UewTHAKeY2evAvQSHhP43MNTMasI2DcC6QhO7\n+x3u3uTuTaNGjYqwTBGReIssCNz9BndvcPdxwNnAE+5+HvAkcGbY7ELgoahqEBGR0qrxO4LrgK+Z\n2asE5wx+WoUaREQkVFO6ye5z96eAp8LuNcBRlViuiIiUpl8Wi4jEnIJARCTmFAQiIjGnIBARiTkF\ngYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxV5F7DVXLDx9/iWVrN5NMJKhNGMmE\nUZM0kokENe39Of8mqE3m9tckC7erSWYPS2TG5Q3vtN2uWgq3SxgED3QTEYlWnw6CVNppbUuzM50i\nlU6zM+Wk0sFr565/06TSTluqY3+1dQirZBBgmcBJFAipTLDkBFeHkOok+LLHJ8tslxWwpQM3QTJp\nmXZhf3Y7BaBIZfXpILhh5iG7NX26jMDYNb5AkBRsl/acUGpLO6lUOm98Vru0k0oF/bvmlSocZjvD\ncTvTadpSaba3Fa4t0y5rGVnzS6WrG4IJIxNyyQLhUyCUSu95ZUI0e0+s9N6ekUx2EmhhfyIBCTMS\nFowzg6QZiYSFwyG5qzu3fc64RNhvQRgmw/7s+WQvR3uN0lP6dBDsrkTC6Jdo/4+WrGotleSeCYZM\nEHUSaPmh0iGkcsMmCMh0gQAt0S4rEEu1296WKljPznQ6ax6FQ763sTAcgvDIDpzg89seKrmB09k0\nwbj8ILKwbX7g5QdT9rx2hWF2wGUvJ+wPlpMdjLnhlywQmlZk+eXUlj+vQkHdIYzD95HMqy+n1gJ/\ng94S1AoC6cAs/IYdn+zbpcNeXKr4nlcq7aQd0u6kw+5U2oMw9XBc2kmH4Zp2Oh3nTjg8d17p9mFl\nL4esaYJ+z+vurLbMNEE97d2ptPNRqkRt7fNyJ11kObnvk13TeO/L4ZJyAzE3gLODOifwErkh+rML\nj2T/EQMirVNBIJIlmTCSiRgm4B7APTeMckIiXSAkd3UXDsnskNoVmiUCr9C4cueVO65wGHecpvNx\n7cvvXxv9xZ0KAhHZIwSHoCBJ7zic0pfodwQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhT\nEIiIxJyCQEQk5sx7we+6zawFeKObk48ENvRgOT1FdXWN6uoa1dU1fbWuA9x9VKlGvSIIdoeZNbt7\nU7XryKe6ukZ1dY3q6pq416VDQyIiMacgEBGJuTgEwR3VLqATqqtrVFfXqK6uiXVdff4cgYiIFBeH\nPQIRESmiVweBmX3WzF42s1fN7PoC4/ub2X3h+EVmNi5r3A3h8JfN7KQK1/U1M3vRzF4wsz+Z2QFZ\n41JmtjR8/abCdV1kZi1Zy78sa9yFZvZK+LqwwnX9KKum1Wa2OWtcJOvLzH5mZuvNbEUn483MfhzW\n/IKZHZE1Lsp1Vaqu88J6lpvZX8xsata418PhS82sucJ1HW9m72f9rb6VNa7o3z/iuq7NqmlF+Hka\nHo6Lcn3tZ2ZPhtuBlWZ2dYE2lfuMuXuvfBE8RPjvwASgH7AMODSvzZeBuWH32cB9YfehYfv+wPhw\nPskK1vVpYEDY/aX2usL+rVVcXxcB/1pg2uHAmvDfYWH3sErVldf+SuBnFVhfxwJHACs6GT8TeAww\n4BPAoqjXVZl1Hd2+POBz7XWF/a8DI6u0vo4HHt7dv39P15XX9mTgiQqtr72BI8LuQcDqAv8fK/YZ\n6817BEcBr7r7Gnf/CLgXODWvzanAXWH3/cAJZmbh8HvdfYe7vwa8Gs6vInW5+5Puvi3s/RvQ0EPL\n3q26ijgJ+IO7v+fum4A/AJ+tUl3nAL/soWV3yt0XAu8VaXIqMM8DfwOGmtneRLuuStbl7n8JlwuV\n+2yVs746szufy56uqyKfLQB3f9vdl4TdW4BVwL55zSr2GevNQbAv8J9Z/WvpuCJ3tXH3ncD7wIgy\np42yrmyXEqR+uzozazazv5nZaT1UU1fqOiPcDb3fzPbr4rRR1kV4CG088ETW4KjWVymd1R3luuqq\n/M+WA783s8VmdkUV6vmkmS0zs8fMbHI4bI9YX2Y2gGBj+quswRVZXxYcsj4cWJQ3qmKfMT2zuIrM\n7HygCTgua/AB7r7OzCYAT5jZcnf/e4VK+i3wS3ffYWZfINibmlGhZZfjbOB+d09lDavm+tpjmdmn\nCYLgU1mDPxWuq9HAH8zspfAbcyUsIfhbbTWzmcCvgYMrtOxynAz8h7tn7z1Evr7MrJ4gfL7q7h/0\n5Ly7ojfvEawD9svqbwiHFWxjZjXAEGBjmdNGWRdm9l+AG4FT3H1H+3B3Xxf+uwZ4iuCbQkXqcveN\nWbXcCfxDudNGWVeWs8nbdY9wfZXSWd1RrquymNlhBH+/U919Y/vwrHW1HniQnjscWpK7f+DuW8Pu\nR4FaMxvJHrC+QsU+W5GsLzOrJQiB+e7+QIEmlfuMRXEipBIvgr2ZNQSHCtpPMk3Oa/MVck8WLwi7\nJ5N7sngNPXeyuJy6Dic4QXZw3vBhQP+weyTwCj104qzMuvbO6j4d+JtnTk69FtY3LOweXqm6wnaT\nCE7eWSXWVzjPcXR+8nMWuSfyno16XZVZ1/4E57yOzhs+EBiU1f0X4LMVrGts+9+OYIP6Zrjuyvr7\nR1VXOH4IwXmEgZVaX+F7nwfcWqRNxT5jPbayq/EiOKu+mmCjemM47DsE37IB6oD/F/7HeBaYkDXt\njeF0LwOfq3BdfwTeBZaGr9+Ew48Glof/GZYDl1a4ru8DK8PlPwlMypr2knA9vgpcXMm6wv6bgR/k\nTRfZ+iL4dvg20EZwDPZS4IvAF8PxBtwW1rwcaKrQuipV153ApqzPVnM4fEK4npaFf+MbK1zXP2V9\ntv5GVlAV+vtXqq6wzUUEF49kTxf1+voUwTmIF7L+VjOr9RnTL4tFRGKuN58jEBGRHqAgEBGJOQWB\niEjMKQhERGJOQSAiEnMKApEIhHfbfLjadYiUQ0EgIhJzCgKJNTM738yeDe85f7uZJc1sa/gMhJUW\nPC9iVNh2WnhzuxfM7EEzGxYOP8jM/hjeUG2JmR0Yzr4+vHnfS2Y2P7zzLWb2A8s8j+J/VOmti+yi\nIJDYMrNDgDnAMe4+DUgB5xHcUqDZ3ScDTwPfDieZB1zn7ocR/NKzffh84DZ3n0rwa+e3w+GHA18l\neP7FBOAYMxtBcPuOyeF8vhvtuxQpTUEgcXYCwY31njOzpWH/BCAN3Be2+QXwKTMbAgx196fD4XcB\nx5rZIGBfd38QwN1bPfOsiWfdfa27pwluITCO4FborcBPzezzQHtbkapREEicGXCXu08LXxPd/eYC\n7bp7H5YdWd0poMaD52IcRfDg1P4rAAAA1UlEQVSgpNnA492ct0iPURBInP0JODO83zxmNjx8+E0C\nODNscy7wjLu/D2wys+nh8AuApz14utTa9ofiWPCc7AGdLTC8//wQD27FfA0wtbO2IpWiB9NIbLn7\ni2Z2E8FTqBIEd6j8CvAhcFQ4bj3BeQSAC4G54YZ+DXBxOPwC4HYz+044j7OKLHYQ8JCZ1RHskXyt\nh9+WSJfp7qMiecxsq7vXV7sOkUrRoSERkZjTHoGISMxpj0BEJOYUBCIiMacgEBGJOQWBiEjMKQhE\nRGJOQSAiEnP/H785TdPQUrTAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-23989ad082e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model3.fit(X_train[:,:prefix,:], {'act_output':X_train[:,prefix,:10], 'time_output':X_train[:,prefix,10]}, epochs=50, batch_size=batch_size,validation_split=0.2,callbacks=[plot]\n\u001b[0;32m----> 2\u001b[0;31m           ,verbose=0)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfp0j-6Wd_Ba",
        "colab_type": "code",
        "outputId": "84696075-9add-498b-8c92-d1997122497d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "accr = model3.evaluate(X_test[:,:prefix,:],{'act_output':X_test[:,prefix,:10], 'time_output':X_test[:,prefix,10]})\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  act_output_acc: {:0.3f} \\n  time_output_mean_absolute_error: {:0.3f}'.format(accr[0],accr[3],accr[4]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761/761 [==============================] - 0s 113us/step\n",
            "Test set\n",
            "  Loss: 45.408\n",
            "  act_output_acc: 0.645 \n",
            "  time_output_mean_absolute_error: 3.315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16jyjtz0pHir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model3.save(\"p5s1bpi.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f76Mzd-Gpi_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        " \n",
        "# # load model\n",
        "# p2 = load_model('p5s1bpi.h5')\n",
        "# # summarize model.\n",
        "# p2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRryMh_zEYpa",
        "colab_type": "text"
      },
      "source": [
        "**Attention layer implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mhFTKqOilrig"
      },
      "source": [
        "**PREFIX = decide here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no7OwgRi18vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(Layer):\n",
        "    '''attention layer which inputs a layer \n",
        "    and according to the shape of the current \n",
        "    input, outputs augmented layer '''\n",
        "    def __init__(self, nb_head, size_per_head, **kwargs):\n",
        "        self.nb_head = nb_head\n",
        "        self.size_per_head = size_per_head\n",
        "        self.output_dim = nb_head*size_per_head\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.WQ = self.add_weight(name='WQ', \n",
        "                                  shape=(input_shape[0][-1], self.output_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True)\n",
        "        self.WK = self.add_weight(name='WK', \n",
        "                                  shape=(input_shape[1][-1], self.output_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True)\n",
        "        self.WV = self.add_weight(name='WV', \n",
        "                                  shape=(input_shape[2][-1], self.output_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True)\n",
        "        super(Attention, self).build(input_shape)\n",
        "        \n",
        "        \n",
        "#     def Mask(self, inputs, seq_len, mode='mul'):\n",
        "#         if seq_len == None:\n",
        "#             return inputs\n",
        "#         else:\n",
        "#             mask = K.one_hot(seq_len[:,0], K.shape(inputs)[1])\n",
        "#             mask = 1 - K.cumsum(mask, 1)\n",
        "#             for _ in range(len(inputs.shape)-2):\n",
        "#                 mask = K.expand_dims(mask, 2)\n",
        "#             if mode == 'mul':\n",
        "#                 return inputs * mask\n",
        "#             if mode == 'add':\n",
        "#                 return inputs - (1 - mask) * 1e12\n",
        "              \n",
        "    def call(self, x):\n",
        "        if len(x) == 3:\n",
        "            Q_seq,K_seq,V_seq = x\n",
        "            Q_len,V_len = None,None\n",
        "        elif len(x) == 5:\n",
        "            Q_seq,K_seq,V_seq,Q_len,V_len = x\n",
        "        Q_seq = K.dot(Q_seq, self.WQ)\n",
        "        Q_seq = K.reshape(Q_seq, (-1, K.shape(Q_seq)[1], self.nb_head, self.size_per_head))\n",
        "        Q_seq = K.permute_dimensions(Q_seq, (0,2,1,3))\n",
        "        K_seq = K.dot(K_seq, self.WK)\n",
        "        K_seq = K.reshape(K_seq, (-1, K.shape(K_seq)[1], self.nb_head, self.size_per_head))\n",
        "        K_seq = K.permute_dimensions(K_seq, (0,2,1,3))\n",
        "        V_seq = K.dot(V_seq, self.WV)\n",
        "        V_seq = K.reshape(V_seq, (-1, K.shape(V_seq)[1], self.nb_head, self.size_per_head))\n",
        "        V_seq = K.permute_dimensions(V_seq, (0,2,1,3))\n",
        "        A = K.batch_dot(Q_seq, K_seq, axes=[3,3]) / self.size_per_head**0.5\n",
        "        A = K.permute_dimensions(A, (0,3,2,1))\n",
        "#         A = self.Mask(A, V_len, 'add')\n",
        "        A = K.permute_dimensions(A, (0,3,2,1))    \n",
        "        A = K.softmax(A)\n",
        "        O_seq = K.batch_dot(A, V_seq, axes=[3,2])\n",
        "        O_seq = K.permute_dimensions(O_seq, (0,2,1,3))\n",
        "        O_seq = K.reshape(O_seq, (-1, K.shape(O_seq)[1], self.output_dim))\n",
        "#         O_seq = self.Mask(O_seq, Q_len, 'mul')\n",
        "        return O_seq\n",
        "      \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0][0], input_shape[0][1], self.output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyKmvuVOjrT5",
        "colab_type": "code",
        "outputId": "4f3dfa90-b923-4c67-bc94-9ae0c8f9e9dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "#shared model where first layer is common then two layers branch out specializing in activity and time prediction respectively\n",
        "inp = Input((prefix,num_features),name='inp')  \n",
        "x = LSTM(hidden_units,return_sequences=True)(inp)\n",
        "temp= Dropout(0.6)(temp)\n",
        "temp = Attention(2, 64)([x, x, x])  #output: [batch_size, time_step, nb_head*size_per_head]\n",
        "\n",
        "\n",
        "temp = BatchNormalization()(temp)\n",
        "temp = Activation('relu')(temp)\n",
        "temp= Dropout(0.6)(temp)\n",
        "temp = Dense(128,activation='relu')(temp)\n",
        "temp= Dropout(0.6)(temp)\n",
        "temp1 = Dense(128,activation='relu')(temp)\n",
        "temp = Flatten()(temp)\n",
        "temp1 = Flatten()(temp1)\n",
        "\n",
        "act_output = Dense(classes+1, activation='softmax', kernel_initializer='glorot_uniform', name='act_output')(temp1)\n",
        "time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(temp)\n",
        "\n",
        "\n",
        "attmodel = Model(inputs=[inp], outputs=[act_output, time_output])\n",
        "print(attmodel.summary())\n",
        "attmodel.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mean_squared_error'}, optimizer='Adam',metrics = {'act_output':'accuracy', 'time_output':'mae'})\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0703 22:22:59.800151 139885454280576 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inp (InputLayer)                (None, 2, 13)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 2, 100)       45600       inp[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "attention_1 (Attention)         (None, 2, 128)       38400       lstm_8[0][0]                     \n",
            "                                                                 lstm_8[0][0]                     \n",
            "                                                                 lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 2, 128)       512         attention_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 2, 128)       0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 2, 128)       0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 2, 128)       16512       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 2, 128)       0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2, 128)       16512       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 256)          0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 256)          0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "act_output (Dense)              (None, 10)           2570        flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_output (Dense)             (None, 1)            257         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 120,363\n",
            "Trainable params: 120,107\n",
            "Non-trainable params: 256\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NpCyb0CX0FcW",
        "outputId": "640f1733-6404-45f2-db02-390c1639ad1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "history = attmodel.fit(X_train[:,:prefix,:], {'act_output':X_train[:,prefix,:10], 'time_output':X_train[:,prefix,10]}, epochs=5, batch_size=batch_size,validation_split=0.2,callbacks=[plot]\n",
        "          ,verbose=0)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VfW97/H3NwMJMwHCLAk4gYAE\nCYhStMWrUmtRqy2Ox6Hq0+FWa3u9HY631p72HlvP057J6/DYAXucOM51qLUtlWJbIVAGEUVFguBA\nmAmQkOF7//itJJuQZO2E7OwMn9fzrCd7r73W3r9lcH/y+63v+i1zd0RERFqSke4GiIhI56ewEBGR\nWAoLERGJpbAQEZFYCgsREYmlsBARkVgKCxERiaWwEBGRWAoLERGJlZXuBrSXoUOHemFhYbqbISLS\npaxYsWK7u+fHbZfysDCzTKAE2Oru55vZOOBRYAiwArjK3Q81sd93gC8CNcBN7v5SS59TWFhISUlJ\nu7dfRKQ7M7PSZLbriGGom4H1Cc9/DPzM3Y8DdhEC4TBmdhJwKTAJmAf8vyh0REQkDVIaFmY2BvgM\n8ED03IC5wOPRJguBC5vY9QLgUXevdPf3gHeAmalsq4iINC/VPYt/Bf43UBs9HwLsdvfq6PkWYHQT\n+40G3k943uR2ZnajmZWYWUlZWVn7tVpERA6TsrAws/OBbe6+IlWf4e73u3uxuxfn58eenxERkTZK\n5Qnu2cB8MzsPyAUGAP8GDDKzrKh3MQbY2sS+W4FjEp43t52IiHSAlPUs3P077j7G3QsJJ6v/6O5X\nAIuBS6LNrgaeaWL3Z4FLzSwnqp46HliWqraKiEjL0nFR3reAb5jZO4RzGD8HMLP5ZvYDAHdfBywC\n3gB+C3zV3WvS0FYREQGsu9xWtbi42Nt0nUVtDfz++5A/AYZNhPwToVffdm+fiEhnZGYr3L04brtu\ncwV3m+37EJbdD9UV0QqDvEIYdlIIj2ETw+Mhx0FWr3S2VEQkbRQWA8fAdz+AXZtg2xuwbX3Dzw2/\nhbrRr4ysEBh14VH3M68QMnS9oIh0bwoLCF/2Q44Ny8TPNqyvroQd7xweIB/8HdY91bBNVm4YukoM\nkGETYcBoMOv4YxERSQGFRUuycmD4pLAkOrQfyt6MQiRaNr4Cqx9p2CZnwOHDWPkTws9+uh5ERLoe\nhUVb9OoLo6eHJdHBXbDtzYThrPXwxjOw4lcN2/QZeuRQ1rAJkDuwQw9BRLqBbeujP1INzr4jpR+l\nsGhPvfOg4LSw1HGH8m1Hng9Z9RAcKm/YbsCYw3sidZVZ2b07/jhEpPPavx3WPh5C4sNVYJkw6aKU\nf6zCItXMoP/wsBz7qYb1tbWw5/3DA2TbenjvFaipm7HdYPD4hBBJqMzKzE7L4YhIGlRXhoKb1Y/C\n27+D2moYORXm3QmTL+mQ4W2FRbpkZEBeQVhOnNewvqYadm6EsvWHB8lbL4BH8zFmZMPQ44/siQwq\nDO8rIl2fO2wpgdUPw+tPQsVu6DcCZn0Fpl4Gw0/q0OYoLDqbzCzIPyEsJ13QsL6qAna8fXiAbFkO\nrz/RsE12n0aVWVGQ9B+pyiyRrmL3Zlj9WBhm2vkuZPUOVZpTL4Xxn0xbqb7CoqvIzoURU8KSqHIf\nlL11+DmRd34fzonUyRl4ZC9k2EnQd0jHHoOINK1yXyiGWf0obPpzWFc4B+Z8AybOh9wB6W0fCouu\nL6c/jCkOS6L9OxKGsqJl3ZOw4pcN2/QddmSA5J/YKf5hinR7tTWw8U8hINb/BqoPwuBj4VO3wclf\nCEPUnYjCorvqOwT6fgIKP9Gwzh32fXT4CfVtb8DKhVB1oGG7gWMbnVSfCENPUGWWSHvYth5WPQxr\n/ztMN5Q7EIoug6mXhz/6OumQscKiJzGDASPDctxZDetra2F36ZGVWe/+EWqron0zEiqzEnoig48N\n51lEpHnlZfB6Xbnr6jB90HFnw6d/DCfMCxcAd3L6v1xCBdXgcWGZcF7D+poq2PFuCJCyhIsN33y+\noTIrs1fodTQ+JzJwrCqzpGerqmgod33n5ajctQjm/RgmX9zlZnNQWEjzMrPD1eXDJhy+vuogbN9w\neE9k899Ct7pOdt+wX36ja0T6j+i03WyRo+YeqhRXPxIqFSv2hGrE074ayl2HTUx3C9tMYSGtl907\nXBA0curh6yv2HFmZ9fZLsOq/GrbJHXRkae+widBncMceg0h72lUKaxYdWe5adBmMO7NbzEytsJD2\nkzsQjpkZlkTlZY0uMnwzTFdQuadhm34jGp0PiRbdiEo6q4q9DeWupUvDusI5MOebcNL8UKnYjSgs\nJPX65Ydl3BkN69xh7weNTqq/ASW/CCWEEE4CjiyCwtlQMBvGztKEi5JetTWwcXFU7vpcQ7nr3Nvg\n5AUwaGy6W5gyKbutqpnlAkuAHEIoPe7ut5vZXOBfgF7ACuCL7l7dxP41wNro6WZ3n9/S57X5tqrS\nudTWNNyIautKKH01/KytAixclFj4CSg4HcaergsLpWN8/EYYYlqzCMo/CsOpky8O5yE6cblrMpK9\nrWoqw8KAvu5ebmbZwFLgFuAx4Cx332BmPwBK3f3nTexf7u79kv08hUU3duhAOGlY+pcQHluWN9wG\nN39i1PM4PfQ++o9Ib1ul+ygvC0Ubqx+Bj9aEnu7x54SAOOHcLlHumoy034PbQwrVzcGdHS01wCF3\n3xCtfxn4DnBEWIjU69UHxp8ZFggzcNb1OkpfhVWPwPIHwmuDj20YtiqYDYOOSV+7peupqoANL0az\nu74cbqs8ahp8+iehJ9F3aLpbmDYp61kAmFkmYajpOOBu4NvAJuBidy8xs38D5rr7lCb2rQZWAdXA\nne7+dBPb3AjcCDB27NjppaWlqToU6cxqqsOFTnXhUfrXhpPnA8cmhMfp4cLCLjxkICngDu8vCz2I\ndU9G5a6jwpQbUy/t0uWuyUj7MFSjxgwCngK+BvQHfkI4l/E74Hx3L2pin9HuvtXMxgN/JAxdvdvc\nZ2gYSurV1sDH66Jhq6Xh54Ed4bX+IxuGrApmh7mwFB49065SWFM3u+vGMGtz3eyu3aTcNRlpH4ZK\n5O67zWwxMM/d/wWYA2Bm5wAnNLPP1ujnRjP7EzANaDYsROplZMLIk8My60vhL8eytxp6HptebZja\nvc+QKDyik+bDJ/WYL4keqb7c9ZHwbwFCuesZt4ag6Gblru0pZWFhZvlAVRQUvYGzgR+b2TB332Zm\nOcC3gB81sW8ecMDdK81sKDCb0BsRaT2zhivRZ3wxhMfOjQ0nzDe9Gmb9hFCaO/a0hp7HyKma+6qr\nq6mOZnd9BN58LhRHDDkO5v6fMNTUjctd21Mq/y8YCSyMzltkAIvc/Tkzu8vMzo/W3ePufwQws2Lg\nS+5+PTARuM/MaqPt7nT3N1LYVulJzGDIsWE55aqwbvfmw8Njw2/D+l79wkWGdeEx+pRuUwXT7X28\nLip3/e+GctdpV4ZqptHTNfzYSh1yzqIj6JyFtKt9H0XDVn8J4VG2PqzPyoUxM0JwFM6G0cWhWks6\nh/JtYXaA1Q/DR2ujctdzw7Qbx5+joG9CpzrB3REUFpJS+3fA5r9E4bE0fBHh4X7oo6eH8x2Fs+GY\nUzXu3dHqyl1XPRLuEllX7jr18qjcVRdutkRhIZJKB3fD+681DFt98PfwJWWZ4TxHwenhSvOxs6B3\nXrpb2/3Ul7s+DK8/FUql+4+CqQvg5EuPnClZmqWwEOlIleWwZVnDsNXWEqg5BBgMn9zQ8xh7epe7\nj0GnsmsTrI7KXXe9F5W7zo/KXc9QJVsbKCxE0qmqIgRG3bDV+8saJkgcemJDz6PgdBgwKr1t7ewq\n9iTM7voqYDBuTjhRPXE+5CQ9K5A0QWEh0plUH4IPVzUMW23+GxzaF17LG9dwwrzgdBhUoEqd+nLX\nh8OdGasrYMjx4UT1lC9oGpd2pLAQ6cxqquHjtSE46kp2K3aH1waMSZgc8ROhxLenhMdHr4chprX/\nDeUfh/M9ky+Jyl1P6Tn/HTqQwkKkK6mtDeW5m15tuNJ8f1l4rd/wRlOUTOhe9zcv35Ywu+vaUGF2\nwrnhPMTx50JWr3S3sFtTWIh0Ze6w451wvqOu57F3a3it9+AoPKIAGTGl653YraqAt14I5yHqy11P\nCT0Ilbt2qE41N5SItJIZDD0+LMXXhvDYXZowbLU0TF0BkDMglOjWDVuNKoLM7PS2vynuodx41cOw\n7ulQ7jpgNMy+OfQi8k9MdwulBQoLka7ADPIKwzLtirBuz9aGXkfpq/D278L67D6NpiiZDtm56Wo5\n7Hwvmt310ajctW+4R/XUS8Mkfl2tV9RDaRhKpLsoL2uYoqT01TA3Eg6ZOeHWn3X39DhmJvTqm9q2\nVOwJvYfVj4Yr37FwHcTUy6LZXVXu2lnonIVIT3dgZyjRret5fLgavDbMlzRqWkPPY+ypYbbdo1VT\nDRsXh2Gmt14I5a5DTwgBcfIXYOCYo/8MaXcKCxE5XMXecHFgXXhsXQm1VWAZ4SR53T09Ck6HPoOT\nf9+6ctc1i2D/tnACfsolYZhplMpdOzuFhYi07NAB2LK8Yehqy/LQGwAYdlLDsFXBbOg//PB9930c\nlbs+Gq4XqS93rZvdVeWuXYXCQkRap7oy9DbqbkW7+TWo2h9eG3JcCI3hk0Kp6zt/COWuo6eHgJj0\nOZW7dlEqnRWR1snKgYLTwgJQUwUfrmkIj3VPw8qFCeWul0F+k3dFlm5IYSEiTcvMhjHTwzL7Zqit\nCXcUHFTQva4gl6QoLEQkORmZMHhculshaZKyPw/MLNfMlpnZajNbZ2Z3ROvnmtlKM3vdzBaaWZOB\nZWZXm9nb0XJ1qtopIiLxUtmXrATmuvtUoAiYZ2anAwuBS919MlAKHBEEZjYYuB04FZgJ3G5mut2Y\niEiapCwsPCiPnmZHSw1wyN03ROtfBi5uYvdzgZfdfae774q2m5eqtoqISMtSepbKzDLNbBWwjfCF\nvwzIMrO6Mq1LgKbuYjIaeD/h+ZZoXeP3v9HMSsyspKysrH0bLyIi9VIaFu5e4+5FwBjCcNIk4FLg\nZ2a2DNhH6G209f3vd/didy/Oz9d9jUVEUqVD6t/cfTewGJjn7n919znuPhNYAmxoYpetHN7jGBOt\nExGRNEhlNVS+mQ2KHvcGzgbeNLNh0boc4FvAvU3s/hJwjpnlRSe2z4nWiYhIGqSyZzESWGxma4Dl\nhBPWzwG3mtl6YA3wG3f/I4CZFZvZAwDuvhP4p2i/5cAPonUiIpIGmhtKRKQHS3ZuKF2zLyIisRQW\nIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIi\nEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEqtNYWFmWUlsk2tmy8xstZmtM7M7ovVn\nmdlKM1tlZkvN7Lgm9i00s4PRNqvM7N62tFNERNpHs2FhZksTHv+60cvLknjvSmCuu08FioB5ZjYL\nuAe4wt2LgIeB25rZ/113L4qWLyXxeSIikiIt9RD6Jjye1Og1i3tjd3egPHqaHS0eLQOi9QOBD5Jq\nqYiIpE1LYeFtfK2emWUCK4DjgLvd/TUzux54wcwOAnuBWc3sPs7M/h5tc5u7/zmZzxQRkfbXUlgM\nMrOLCENVg8zsc9F6I/QIYrl7DVBkZoOAp8xsMnALcF4UHLcCPwWub7Trh8BYd99hZtOBp81skrvv\nTdzIzG4EbgQYO3ZsMk0SEZE2sDBa1MQLZr9saUd3v7ZVH2T2PeAg8CV3PzZaNxb4rbufFLPvn4D/\n5e4lzW1TXFzsJSXNviwiIk0wsxXuXhy3XbM9i5bCwMyGJ9GAfKDK3XebWW/gbODHwEAzO8HdN0Tr\n1jez7053rzGz8cDxwMa4zxQRkdSILYGtEw0lXQxcDkwERsXsMhJYGJ23yAAWuftzZnYD8ISZ1QK7\ngOui958PFLv794AzgB+YWRVQS+iN7GzdoYmISHtpdhgKIOoRXEAIiGlAf+BCYIm713ZIC5OkYSgR\nkdZLdhiqpessHgbqhor+AygEdrn7nzpbUIiISGq1NAx1EmGYaD2wPjp/kFTJrIhIR6mqqmLLli1U\nVFSkuymdWm5uLmPGjCE7O7tN+7d0grvIzCYAlwG/N7PtQH8zG+7uH7etuSIi7WvLli3079+fwsJC\nzGKvF+6R3J0dO3awZcsWxo0b16b3aHFuKHd/091vd/cJwM3Ag8ByM/tLmz5NRKSdVVRUMGTIEAVF\nC8yMIUOGHFXvK+lqKHdfAawws/8FzGnzJ4qItDMFRbyj/W/UbFiY2b/H7LvkqD5ZRKSb6NevH+Xl\n5fEbdmEt9Sy+BLwOLCJM9qfoFhHpoVo6ZzESuB84F7iKMGvsM+6+0N0XdkTjRES6Enfn1ltvZfLk\nyUyZMoXHHnsMgA8//JAzzjiDoqIiJk+ezJ///Gdqamq45ppr6rf92c9+lubWt6ylaqgdwL3AvWY2\nBrgUeMPMvuXuje9vISLS4z355JOsWrWK1atXs337dmbMmMEZZ5zBww8/zLnnnss//uM/UlNTw4ED\nB1i1ahVbt27l9ddfB2D37t1pbn3Lkrnj3SmE8tmzgRcJU46LiHQ6d/xmHW98sDd+w1Y4adQAbv9s\n41v6NG3p0qVcdtllZGZmMnz4cM4880yWL1/OjBkzuO6666iqquLCCy+kqKiI8ePHs3HjRr72ta/x\nmc98hnPOOadd293eWrqC+wdmtgL4BvAKYd6mL7r7Gx3WOhGRbuCMM85gyZIljB49mmuuuYYHH3yQ\nvLw8Vq9ezSc/+Unuvfderr++8Z0aOpeWeha3Ae8BU6Pl/0alV0a4Ed7JqW+eiEjyku0BpMqcOXO4\n7777uPrqq9m5cydLlizhrrvuorS0lDFjxnDDDTdQWVnJypUrOe+88+jVqxcXX3wxJ554IldeeWVa\n2x6npbBo22V+IiI91EUXXcRf//pXpk6dipnxk5/8hBEjRrBw4ULuuususrOz6devHw8++CBbt27l\n2muvpbY2TLX3z//8z2lufctanHW2K9GssyI90/r165k4cWK6m9ElNPXf6qhnnRUREamjsBARkVgK\nCxERiZXMdRazge8DBdH2ddVQ41PbNBER6SyS6Vn8HPgp8AlgBlAc/WyRmeWa2TIzW21m68zsjmj9\nWWa20sxWmdlSMzuumf2/Y2bvmNlbZnZu8ockIiLtLZkpyve4+4tteO9KYK67l5tZNrDUzF4E7gEu\ncPf1ZvYVwvUc1yTuaGYnEaYXmQSMItx86QR3r2lDO0RE5CglExaLzewu4ElCAADg7itb2slDTW7d\nnL3Z0eLRMiBaP5Awo21jFwCPunsl8J6ZvQPMBP6aRHtFRKSdJRMWp0Y/E+twHZgbt6OZZRLmkjoO\nuNvdXzOz64EXzOwgsBeY1cSuo4G/JTzfEq0TEenSWrr3xaZNmzj//PPrJxfsTGLDwt0/1dY3j4aN\nisxsEPCUmU0GbgHOi4LjVsL5kDZNimJmNwI3AowdO7atzRQRkRgtTSR4ZfTzG00trfkQd98NLAY+\nDUx199eilx4DTm9il63AMQnPx0TrGr/v/e5e7O7F+fn5rWmSiEi7+Pa3v83dd99d//z73/8+P/zh\nDznrrLM45ZRTmDJlCs8880yr37eiooJrr72WKVOmMG3aNBYvXgzAunXrmDlzJkVFRZx88sm8/fbb\n7N+/n8985jNMnTqVyZMn199Hoz211LPoG/3s35Y3NrN8oMrdd5tZb8IU5z8GBkYnqzdE69Y3sfuz\nwMNm9lPCCe7jgWVtaYeI9CAvfhs+Wtu+7zliCnz6zmZfXrBgAV//+tf56le/CsCiRYt46aWXuOmm\nmxgwYADbt29n1qxZzJ8/v1X3wb777rsxM9auXcubb77JOeecw4YNG7j33nu5+eabueKKKzh06BA1\nNTW88MILjBo1iueffx6APXv2HN0xN6Glmx/dF/28o43vPRJYGJ23yAAWuftzZnYD8ISZ1QK7gOsA\nzGw+YRr077n7OjNbBLwBVANfVSWUiHRG06ZNY9u2bXzwwQeUlZWRl5fHiBEjuOWWW1iyZAkZGRls\n3bqVjz/+mBEjRiT9vkuXLuVrX/saABMmTKCgoIANGzZw2mmn8aMf/YgtW7bwuc99juOPP54pU6bw\nzW9+k29961ucf/75zJkzp92PM5kT3G3i7muAaU2sfwp4qon1zxJ6FHXPfwT8KFXtE5FuqIUeQCp9\n/vOf5/HHH+ejjz5iwYIFPPTQQ5SVlbFixQqys7MpLCykoqKiXT7r8ssv59RTT+X555/nvPPO4777\n7mPu3LmsXLmSF154gdtuu42zzjqL733ve+3yeXVSFhYiIj3FggULuOGGG9i+fTuvvPIKixYtYtiw\nYWRnZ7N48WJKS0tb/Z5z5szhoYceYu7cuWzYsIHNmzdz4oknsnHjRsaPH89NN93E5s2bWbNmDRMm\nTGDw4MFceeWVDBo0iAceeKDdj1FhISJylCZNmsS+ffsYPXo0I0eO5IorruCzn/0sU6ZMobi4mAkT\nJrT6Pb/yla/w5S9/mSlTppCVlcWvfvUrcnJyWLRoEb/+9a/Jzs5mxIgRfPe732X58uXceuutZGRk\nkJ2dzT333NPuxxh7Pwszuxn4JbAPeIAwtPRtd/9du7fmKOh+FiI9k+5nkbxU38/iOnffC5wD5AFX\nAekZGBQRkbRIZhiqrtbrPODXUaVS8vVfIiJymLVr13LVVVcdti4nJ4fXXnutmT3SL5mwWGFmvyPc\nk/s7ZtYfqE1ts0REuq8pU6awatWqdDejVZIJiy8CRcBGdz9gZoOBa1PbLBGR5Ll7qy5464nizk/H\nSeacxWnAW9GV2FcSphRv/8sDRUTaIDc3lx07dhz1l2F35u7s2LGD3NzcNr9HMj2Le4CpZjYV+Cah\nIupB4Mw2f6qISDsZM2YMW7ZsoaysLN1N6dRyc3MZM2ZMm/dPJiyq3d3N7ALgP93952b2xTZ/oohI\nO8rOzmbcuHHpbka3l0xY7DOz7xBKZueYWQbhRkYiItJDJHPOYgHhDnnXuftHhOnC70ppq0REpFOJ\nDYsoIB4iTC1+PlDh7g+mvGUiItJpxIaFmX2BcC+JzwNfAF4zs0tS3TAREek8kjln8Y/ADHffBvU3\nNfo98HgqGyYiIp1HMucsMuqCIrIjyf1ERKSbSKZn8Vszewl4JHq+AHghdU0SEZHOJjYs3P1WM7sY\nmB2tuj+6252IiPQQSd38yN2fAJ5ozRubWS6wBMiJPudxd7/dzP4M9I82GwYsc/cLm9i/Bqi78/pm\nd5/fms8XEZH202xYmNk+oKnJVgxwdx8Q896VwFx3LzezbGCpmb3o7vV3EjezJ4Bnmtn/oLsXxXyG\niIh0gGbDwt37N/daMjzM6lUePc2OlvrwMbMBwFw0g62ISKeX0qomM8s0s1XANuBld0+8s8eFwB+i\nu/A1JdfMSszsb2Z2xDCViIh0nJSGhbvXRENJY4CZZjY54eXLaKiwakpBdF/Yy4F/NbNjG29gZjdG\ngVKiGSdFRFKnQ66XcPfdwGJgHoCZDQVmAs+3sM/W6OdG4E/AtCa2ud/di929OD8/PwUtFxERSGFY\nmFm+mQ2KHvcGzgbejF6+BHjO3Sua2TfPzHKix0MJZbtvpKqtIiLSslT2LEYCi81sDbCccM7iuei1\nS2k0BGVmxWb2QPR0IlBiZqsJPZI73V1hISKSJtZdbkVYXFzsJSUl6W6GiEiXYmYrovPDLdIcTyIi\nEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJL\nYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrFSFhZmlmtmy8xstZmtM7M7ovV/\nNrNV0fKBmT3dzP5Xm9nb0XJ1qtopIiLxslL43pXAXHcvN7NsYKmZvejuc+o2MLMngGca72hmg4Hb\ngWLAgRVm9qy770phe0VEpBkp61l4UB49zY4Wr3vdzAYAc4GmehbnAi+7+84oIF4G5qWqrSIi0rKU\nnrMws0wzWwVsI3z5v5bw8oXAH9x9bxO7jgbeT3i+JVonIiJpkNKwcPcady8CxgAzzWxywsuXAY8c\nzfub2Y1mVmJmJWVlZUfzViIi0oIOqYZy993AYqKhJDMbCswEnm9ml63AMQnPx0TrGr/v/e5e7O7F\n+fn57dtoERGpl8pqqHwzGxQ97g2cDbwZvXwJ8Jy7VzSz+0vAOWaWZ2Z5wDnROhERSYNU9ixGAovN\nbA2wnHDO4rnotUtpNARlZsVm9gCAu+8E/inabznwg2idiIikgbl7/FZdQHFxsZeUlKS7GSIiXYqZ\nrXD34rjtdAW3iIjEUliIiEgshYWIiMRSWIiISCyFhYiIxFJYiIhILIWFiIjEUliIiEgshYWIiMRS\nWIiISCyFhYiIxErlbVVFWs3debesnOWbdvHRngp698qkT69Memdn0qdXFn2i5316ZdW/1qdXJr17\nZdIrMwMzS/chiHRLCgtJq8rqGl7fuoflm3ZRsmkXK0p3sutAVZveKzPD6JMdgqNvTlYUMJkJoRIF\nTLS+T07WEUF0eABlhW1zFEQiCgvpUHsOVLFi806Wb9rFik27WLVlN4eqawEYP7QvZ580nOKCwRQX\n5lE4pC8V1TXsr6zh4KEaDlRVc+BQ9PhQDQcOVR/2+ED0OGxbw8Fo3b6KarbtrWR/wvYHq2pa1e7E\nIKoPkoReT9+cw4OodxPhk9gzqgui3r0yyclSEEnnp7CQlHF3tuw6SElpQzi89fE+ALIyjMmjB3L1\naQVMj8JhaL+cI94jfMG2/z/T2lqnorrmiPA50EQQHaxqeO3goRr2HzoyiA5UJQZX64Iow6jv9fRt\nIogah1OTvaDsxCDKpG/0fgoiaS8KC2k3NbXO+g/3UrJpJ8tLQzh8tDfcDLF/ThanFOTx2akjmV4w\nmKJjBtG7V2ba2pqRYR0eRPWPo17P/sojg6i+d1RVTXnlkUF0sKqG1tyCJjGIEsOn2XCq7x1lHTZ8\nl/h67+xMcqMlM0NB1FMoLKS1BXbEAAAMBklEQVTNDhyqZtXm3eF8Q+lO/r55N+WV1QCMHJjLzHGD\nmVGYx/SCwZw4on+P+WJJZRC5OxVVtQ0BUxUFTGX1YUF02JBcFD77KxMeH6pme3llwnbVHGhlEAH0\nyswgJzuD3Oy6EMmoD5Lc7ExyszLo3SuT3KzotfrHmfRuvO1h7xOe987OJCdal51p6iWlkcJCkrZt\nXwUrNu2qD4d1H+ylptYxgxOH9+eiaaMpLsyjuHAwowf1TndzuyUzC3/d98pkSDu/d7NBlDgkF62v\nqKqhoqq2/nFldXitoqqWiujxnoNVfHyohorqsM3BQzVUVNfWn6NqrQzjsDDJicKkcbDkZmXSu1dG\nQyhFw3HNBVHuYe8TtsnJyiCjh/xxk6yUhYWZ5QJLgJzocx5399st/GnwQ+DzQA1wj7v/exP71wBr\no6eb3X1+qtoqRwolrPvDkFIUDqU7DgCQk5VB0TGD+PKZx1JcmMe0sXkM7J2d5hbL0UplECWqG6ar\nqKoNIZIQPhVNBFFFo9cPVjWEUkV9GNWya38VFdU1VCbs29phu0R1AZMYJjmJPaKs8N8qNzuDnLrH\nUQ+q7nFOE0F0eO8rPM7O7PyXvKWyZ1EJzHX3cjPLBpaa2YvAROAYYIK715rZsGb2P+juRSlsnyQI\nJax768MhsYR1cN9eFBfkceWpBRQX5jFp1EB6ZXX+f9zSOTUM06X+s9ydQzW1rQ+iRq/Vb19dS8Wh\nGnbuP9Tk9lU1bUumrAw7LDxih/Wix3XDeqMG5TJv8sh2/q/XqI2pemN3d6A8epodLQ58Gbjc3Wuj\n7balqg3SvD0Hqli5eRfLN+2kpFEJ67ihffkfE4czo3Aw0wvzGD+0r8aKpUsyM3KyMsnJyuyQ3m9N\nrTfqLTUdRAeraqg8IrhqG9YnDOuVV1ZTtq+Syuoje2J1po0d1HXDAsDMMoEVwHHA3e7+mpkdCyww\ns4uAMuAmd3+7id1zzawEqAbudPenU9nW7szd2br7ICWbGsIhsYR10uiB/MOsAooLBzO9II/8/keW\nsIpIvMwMo29OFn1zUn862N3rA6S2jUNtrZHSI3L3GqDIzAYBT5nZZMI5jAp3LzazzwG/AOY0sXuB\nu281s/HAH81srbu/m7iBmd0I3AgwduzYVB5Kl1JT67z50d7DwiGxhHVaQR7nnzyS4sL0l7CKSNuY\nWf3wVEfokGood99tZouBecAW4MnopaeAXzazz9bo50Yz+xMwDXi30Tb3A/cDFBcXd0C2dk51Jawl\npSEcGpewzohKWIt7WAmriLSfVFZD5QNVUVD0Bs4Gfgw8DXwKeA84E9jQxL55wAF3rzSzocBs4Cep\namtXU1fCWlK6i5JNO3m9UQnrhdNGMaNwsEpYRaTdpLJnMRJYGJ23yAAWuftzZrYUeMjMbiGcAL8e\nwMyKgS+5+/WEiqn7zKw22vdOd38jhW3ttBJLWOvCYVNCCevUYwbxpTPHU1w4mFNUwioiKWLe1iLk\nTqa4uNhLSkrS3Yyjdqi6lrVb97Cibj6l0l3s3H8ICCWs0wvywpBS4WAmq4RVRI6Sma1w9+K47XQF\nd5rtOVjFytJd9ZPtrX5/N5UJJaxzJwyrDweVsIpIuigsOlBiCWtJaUMJq3tDCeuVswrq51NSCauI\ndBYKixRKLGGtO9/w4Z5QwtovmoX1vCkjKS7Mo+iYQSmZeE5EpD3o26kdHThUzar3d9eHw8rSXfUl\nrCMG5FJcmBdVKeUxYcQAlbCKSJehsDgKZfsq609El5TuYt3WPVQnlLBeUDSqPhxGD+qt8w0i0mUp\nLJLk7mzcvj9hor1dvLd9PwC9ollYbzxjPDPqSlj7qIRVRLoPhUUzDlXX8voHew4Lh7oS1rw+2RQX\nDubSGceEEtbRA8jJ0pQZItJ9KSwiew6GWVjrwiGxhLVwSB/mThhGcUEoYT02XyWsItKz9Piw+GD3\nQa771fL6EtbMDGPyqAFcOauA4oI8phfmMax/brqbKSKSVj0+LIb1z2H0oN6hhLUgj6KxKmEVEWms\nx38rZmVm8PNrZqS7GSIinZomFhIRkVgKCxERiaWwEBGRWAoLERGJpbAQEZFYCgsREYmlsBARkVgK\nCxERidVt7sFtZmVA6VG8xVBgezs1J526y3GAjqWz6i7H0l2OA47uWArcPT9uo24TFkfLzEqSuWl5\nZ9ddjgN0LJ1VdzmW7nIc0DHHomEoERGJpbAQEZFYCosG96e7Ae2kuxwH6Fg6q+5yLN3lOKADjkXn\nLEREJJZ6FiIiEqtHhYWZzTOzt8zsHTP7dhOv55jZY9Hrr5lZYce3MjlJHMs1ZlZmZqui5fp0tDOO\nmf3CzLaZ2evNvG5m9u/Rca4xs1M6uo3JSuJYPmlmexJ+J9/r6DYmw8yOMbPFZvaGma0zs5ub2KZL\n/F6SPJau8nvJNbNlZrY6OpY7mtgmdd9h7t4jFiATeBcYD/QCVgMnNdrmK8C90eNLgcfS3e6jOJZr\ngP9Md1uTOJYzgFOA15t5/TzgRcCAWcBr6W7zURzLJ4Hn0t3OJI5jJHBK9Lg/sKGJf19d4veS5LF0\nld+LAf2ix9nAa8CsRtuk7DusJ/UsZgLvuPtGdz8EPApc0GibC4CF0ePHgbPMzDqwjclK5li6BHdf\nAuxsYZMLgAc9+BswyMxGdkzrWieJY+kS3P1Dd18ZPd4HrAdGN9qsS/xekjyWLiH6b10ePc2OlsYn\nnVP2HdaTwmI08H7C8y0c+Y+mfht3rwb2AEM6pHWtk8yxAFwcDRE8bmbHdEzT2l2yx9pVnBYNI7xo\nZpPS3Zg40TDGNMJfsYm63O+lhWOBLvJ7MbNMM1sFbANedvdmfy/t/R3Wk8Kip/kNUOjuJwMv0/DX\nhqTPSsLUClOB/wCeTnN7WmRm/YAngK+7+950t+doxBxLl/m9uHuNuxcBY4CZZja5oz67J4XFViDx\nr+sx0bomtzGzLGAgsKNDWtc6scfi7jvcvTJ6+gAwvYPa1t6S+b11Ce6+t24Ywd1fALLNbGiam9Uk\nM8smfLk+5O5PNrFJl/m9xB1LV/q91HH33cBiYF6jl1L2HdaTwmI5cLyZjTOzXoSTP8822uZZ4Oro\n8SXAHz06U9TJxB5Lo/Hj+YSx2q7oWeAfouqbWcAed/8w3Y1qCzMbUTd+bGYzCf//dbo/RqI2/hxY\n7+4/bWazLvF7SeZYutDvJd/MBkWPewNnA2822ixl32FZ7fEmXYG7V5vZ/wReIlQT/cLd15nZD4AS\nd3+W8I/q12b2DuFE5aXpa3HzkjyWm8xsPlBNOJZr0tbgFpjZI4RqlKFmtgW4nXDiDne/F3iBUHnz\nDnAAuDY9LY2XxLFcAnzZzKqBg8ClnfSPkdnAVcDaaHwc4LvAWOhyv5dkjqWr/F5GAgvNLJMQaIvc\n/bmO+g7TFdwiIhKrJw1DiYhIGyksREQklsJCRERiKSxERCSWwkJERGIpLETSKJrx9Ll0t0MkjsJC\nRERiKSxEkmBmV0b3ElhlZvdFE7qVm9nPonsL/MHM8qNti8zsb9Ekjk+ZWV60/jgz+300Yd1KMzs2\nevt+0WSPb5rZQwlXE98Z3YdhjZn9S5oOXQRQWIjEMrOJwAJgdjSJWw1wBdCXcOXsJOAVwhXbAA8C\n34omcVybsP4h4O5owrrTgbrpMaYBXwdOItyjZLaZDQEuAiZF7/PD1B6lSMsUFiLxziJMxLg8mjLi\nLMKXei3wWLTNfwGfMLOBwCB3fyVavxA4w8z6A6Pd/SkAd69w9wPRNsvcfYu71wKrgELC1NIVwM/N\n7HOEKTVE0kZhIRLPgIXuXhQtJ7r795vYrq1z51QmPK4BsqJ7Ecwk3MDmfOC3bXxvkXahsBCJ9wfg\nEjMbBmBmg82sgPD/zyXRNpcDS919D7DLzOZE668CXonu0rbFzC6M3iPHzPo094HR/RcGRlNm3wJM\nTcWBiSSrx8w6K9JW7v6Gmd0G/M7MMoAq4KvAfsINaG4j3LlsQbTL1cC9URhspGFG1quA+6JZQquA\nz7fwsf2BZ8wsl9Cz+UY7H5ZIq2jWWZE2MrNyd++X7naIdAQNQ4mISCz1LEREJJZ6FiIiEkthISIi\nsRQWIiISS2EhIiKxFBYiIhJLYSEiIrH+P8zC7iVlJhALAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-40b38bad3c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = attmodel.fit(X_train[:,:prefix,:], {'act_output':X_train[:,prefix,:10], 'time_output':X_train[:,prefix,10]}, epochs=5, batch_size=batch_size,validation_split=0.2,callbacks=[plot]\n\u001b[0;32m----> 2\u001b[0;31m           ,verbose=0)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GHjuDbkp0Fcb",
        "outputId": "df862f02-620a-48aa-84f3-633819104743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "accr = attmodel.evaluate(X_test[:,:prefix,:],{'act_output':X_test[:,prefix,:10], 'time_output':X_test[:,prefix,10]})\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  act_output_acc: {:0.3f} \\n  time_output_mean_absolute_error: {:0.3f}'.format(accr[0],accr[3],accr[4]))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761/761 [==============================] - 0s 106us/step\n",
            "Test set\n",
            "  Loss: 40.212\n",
            "  act_output_acc: 0.766 \n",
            "  time_output_mean_absolute_error: 3.501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De56XMyT6Za0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Suffix prediction and remaining cycle time prediction starts here\n",
        "prefix =3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Ed1zuFEunJ0",
        "colab": {}
      },
      "source": [
        "# similar process from above where we remove the traces who fall short of the prefix length taken\n",
        "X_train = X[X[:,prefix-1,0] == 0]\n",
        "time = padded_time[X[:,prefix-1,0] == 0]\n",
        "# time.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BzdgMYelunKI",
        "colab": {}
      },
      "source": [
        "#data is divided into test and train\n",
        "till = int(X_train.shape[0] *0.8)\n",
        "X_test = X_train[till:]\n",
        "X_train = X_train[:till]\n",
        "# X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cp3pttrrunKO",
        "colab": {}
      },
      "source": [
        "time_test = time[till:]\n",
        "time_train = time[:till]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg9jxb8oT5O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ZBNX98scP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The weights corresponding to different prefixes are saved and loaded here\n",
        "# p2 = load_model('p2s1.h5')\n",
        "# p3 = load_model('p3s1.h5')\n",
        "# p4 = load_model('p4s1.h5')\n",
        "# p5 = load_model('p5s1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3LjToyx1Y01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we calculate the previous time because we have to add the new elapsed time to it to form the new timestamp\n",
        "prevtime = time_test[:,prefix - 1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LnQ0HWqx-ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pref = prefix#because the value of prefix will change so we want to store it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFhzxmT7yYhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prevtime and last_time are same but used for different purposes in the code\n",
        "last_time = time_test[:,prefix-1]\n",
        "# last_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2eFy3aI4XV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We take the ground truth value of the future four events timestamp\n",
        "time_test = time_test[:,prefix:prefix+4]\n",
        "# time_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bk2yLXIGf-A",
        "colab_type": "code",
        "outputId": "7b5faa92-f21f-4457-a1d7-1563e690cb5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#seq will contain future suffix of each example in test case\n",
        "#time_pred will contain the time of the above said predicted suffix\n",
        "seq = []\n",
        "time_pred = []\n",
        "# endtime = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  seq.append([])\n",
        "  time_pred.append([])\n",
        "prefix=2\n",
        "testX = X_test[:,:prefix,:]#we take the input according to the specified prefix\n",
        "# print(prevtime[2])\n",
        "testnum = 1\n",
        "print(\"For instance we follow the test case with index 1 and see the predictions\")\n",
        "while(True):\n",
        "  #pact is predicted activity in one-hot encoded form\n",
        "  #ptime is predicted elapsed time in days.\n",
        "  if (prefix == 2):\n",
        "    pact,ptime=p2.predict(testX)\n",
        "  elif (prefix == 3):\n",
        "    pact,ptime=p3.predict(testX)\n",
        "  elif (prefix == 4):\n",
        "    pact,ptime=p4.predict(testX)\n",
        "  elif (prefix == 5):\n",
        "    pact,ptime=p5.predict(testX)\n",
        "  else:\n",
        "    #we predict only next 4 which is more than enough given the low number of events in the traces\n",
        "    break\n",
        "  \n",
        "  preact = np.argmax(pact,axis = 1)\n",
        "  #at this point for many traces end of trace i.e 0 would have occurred \n",
        "  #but we keep predicting forward and handle this issue afterwards in post-processing\n",
        "  newtime = []\n",
        "  for i in range( len(ptime)):\n",
        "    newtime.append( np.timedelta64( int((ptime*86400)[:,0][i] )  ,'s') + prevtime[i] )\n",
        "  newtime = np.array(newtime)\n",
        "  \n",
        "\n",
        "  for i in range( len(ptime)):\n",
        "    seq[i].append(preact[i])\n",
        "    time_pred[i].append(newtime[i])\n",
        "  print ( \"\\n\"+str(testnum)+\":Next activity is \" + str(preact[testnum]) + \" performed at time \"+ str(newtime[testnum]) + \" (previous activity time:\" + str(prevtime[testnum]) + \")\")\n",
        "  \n",
        "  act = np.zeros(( len(ptime),10))\n",
        "  prefix += 1\n",
        "  for i in range( len(ptime)): \n",
        "    act[i,preact[i]] = 1\n",
        "  act = act.reshape(-1,1,10)\n",
        "  \n",
        "  test = pd.DataFrame(newtime)\n",
        "  mid = []\n",
        "  sun = []\n",
        "  elapsed = []\n",
        "  for i in range( len(ptime)):\n",
        "    mid.append( (test[0][i].hour*3600 + test[0][i].minute*60 + test[0][i].second)/84600 )\n",
        "    sun.append( test[0][i].weekday() + mid[i] )\n",
        "    elapsed.append( (test[0][i] - prevtime[i]).total_seconds()/86400 )\n",
        "  mid = np.array(mid)\n",
        "  sun = np.array(sun)\n",
        "  elapsed = np.array(elapsed)\n",
        "  mid = mid.reshape(-1,1,1)\n",
        "  sun = sun.reshape(-1,1,1)\n",
        "  elapsed = elapsed.reshape(-1,1,1)\n",
        "  new = np.concatenate((act,mid,sun,elapsed),axis = 2 )\n",
        "  X_new = np.concatenate ((testX,new) , axis = 1)\n",
        "  #above, we extract information from the predicted data and concatenate it to our already given prefix to form\n",
        "  #a new prefix to predict next activity and timestamp in the sequence.\n",
        "\n",
        "#   truth = (preact != 0)\n",
        "  prevtime = newtime\n",
        "  testX = X_new\n",
        "#   break"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For instance we follow the test case with index 1 and see the predictions\n",
            "\n",
            "1:Next activity is 6 performed at time 2012-02-03T19:24:34.000000000 (previous activity time:2012-01-27T18:20:57.000000000)\n",
            "\n",
            "1:Next activity is 0 performed at time 2012-02-04T02:29:40.000000000 (previous activity time:2012-02-03T19:24:34.000000000)\n",
            "\n",
            "1:Next activity is 6 performed at time 2012-02-24T22:38:24.000000000 (previous activity time:2012-02-04T02:29:40.000000000)\n",
            "\n",
            "1:Next activity is 6 performed at time 2012-03-09T20:22:46.000000000 (previous activity time:2012-02-24T22:38:24.000000000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP5ttH3KmUql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For each trace zero i.e end of trace would have occurred or worst case scenario end of trace,\n",
        "# we note down the index of that using zerofirst\n",
        "zerofirst = []\n",
        "for li in seq:\n",
        "  for i in range(len(li)):\n",
        "    if (li[i] == 0 or i == len(li)-1):\n",
        "      li[i:] = [0]*(len(li)- i)\n",
        "      zerofirst.append(i)\n",
        "      break\n",
        "# max(zerofirst)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfz8VFmiyIgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prefix = pref"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSO78S8N6f-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we note down the ground truth suffix for comparison purpose\n",
        "suffix = X_test[:,prefix:prefix+6-pref,:10]\n",
        "# suffix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_IHv9Vz7mRV",
        "colab_type": "code",
        "outputId": "1c31ff9c-36c4-47a8-84f1-035aa68cfd06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#convert one-hot encoding to the actual value of the event i.e activity ID for comparion purposes\n",
        "preact = np.argmax(suffix,axis = 2)\n",
        "# list(preact[:5,:])\n",
        "preact.shape"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(726, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQNypb_kp_Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#similar to zerofirst but zerotest is for the ground truth suffix extracted earliar.\n",
        "zerotest = []\n",
        "for li in preact:\n",
        "  for i in range(len(li)):\n",
        "    if (li[i] == 0 or i == len(li)-1):\n",
        "      li[i:] = [0]*(len(li)- i)\n",
        "      zerotest.append(i)\n",
        "      break\n",
        "      \n",
        "# max(zerotest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzmcwNcjyqML",
        "colab_type": "code",
        "outputId": "a6c2a1aa-37aa-4f0e-af65-77097a8f5fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(zerotest)\n",
        "time_test.shape"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(726, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYpHYdVbzh4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_pred = np.array(time_pred)\n",
        "# time_pred.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns8TBFbo6Os8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i=0\n",
        "# for li in time_pred:\n",
        "#   lmao = zerofirst[i]\n",
        "#   li[lmao:] = [0]*(len(li)- lmao)\n",
        "#   i +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozl7evXy-pTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# time_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keO-Jat_xLTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# zerotest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egg_NabNAgMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is for remaining cycle time prediction, we calculate the last known timestamp from the ground truth suffix\n",
        "i=0\n",
        "last_rec = []\n",
        "for li in time_test:\n",
        "  lmao = zerotest[i]\n",
        "  if (lmao == 0):\n",
        "    last_rec.append(last_time[i])\n",
        "    i+=1\n",
        "    continue\n",
        "  last_rec.append(li[lmao-1])\n",
        "  i +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGUeCkeFKUmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is for remaining cycle time prediction as well, \n",
        "# we calculate the last known timestamp from the predicted suffix\n",
        "\n",
        "i=0\n",
        "last_pred = []\n",
        "for li in time_pred:\n",
        "  lmao = zerofirst[i]\n",
        "  if (lmao == 0  ):\n",
        "#     print(i,last_time[i]);\n",
        "    last_pred.append(last_time[i])\n",
        "    i+=1\n",
        "    continue\n",
        "  last_pred.append(li[lmao-1])\n",
        "  i +=1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uTvLiJOLfst",
        "colab_type": "code",
        "outputId": "a260af07-1fb9-4d81-c2a5-5f6360fee7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#for the above two array created we find the difference in time \n",
        "diff = []\n",
        "\n",
        "for i in range(len(last_pred)):\n",
        "  if (last_pred[i] != 0):\n",
        "    dt = last_pred[i]- last_rec[i]\n",
        "    seconds = dt / np.timedelta64(1, 's')\n",
        "    diff.append(abs(seconds/86400))\n",
        "  "
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWUxmXaRNfBx",
        "colab_type": "code",
        "outputId": "ccc57bac-1d12-4176-994f-721522b71fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\" the result of remaining time cycle prediciton in MAE is :\"+ str(sum(diff)/len(diff)))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the result of remaining time cycle prediciton in MAE is :3.3437819482705855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Bt77_5OUnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for suffix prediction we have to convert them into string format\n",
        "#for each suffix we find the string version with last element as zero\n",
        "lpred = []\n",
        "for li in seq:\n",
        "  s = \"\"\n",
        "  flag = 1\n",
        "  for x in li:\n",
        "    if (x !=0 ):\n",
        "#       if (x ==0):\n",
        "#         flag =0\n",
        "      s+=str(x)\n",
        "  lpred.append(s)\n",
        "  \n",
        "  \n",
        "# lpred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiHboBbgzLFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#similar to above, we find the ground truth string version of suffix\n",
        "ltruth = []\n",
        "for li in preact:\n",
        "  s = \"\"\n",
        "  flag = 1\n",
        "  for x in li:\n",
        "    if (x !=0 ):\n",
        "#       if (x ==0):\n",
        "#         flag =0\n",
        "      s+=str(x)\n",
        "  ltruth.append(s)\n",
        "# ltruth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY1FzH3n0j2A",
        "colab_type": "code",
        "outputId": "f55b2d25-d3ca-4f65-b18c-863ba50d75b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print(\"Installing strsim to calculate DLS\")\n",
        "pip install strsim"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: strsim in /usr/local/lib/python3.6/dist-packages (0.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU0N7P4t1Q-L",
        "colab_type": "code",
        "outputId": "c77d271e-c6d8-4197-9482-11113906b72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from similarity.damerau import Damerau\n",
        "#below are two example of how it works\n",
        "damerau = Damerau()\n",
        "print(damerau.distance('ABCDEF', 'ABDCE'))\n",
        "print(damerau.distance('ABCDE', 'ABCDE'))\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB-WGwa244kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ltruth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps39UVNz1gO1",
        "colab_type": "code",
        "outputId": "cb6f09fe-1065-43a5-8842-49022f047ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# we calculate the DLS for each suffix and add the result to damdist array\n",
        "damdist = []\n",
        "for i in range(len(lpred)):\n",
        "  if ( (max(len(ltruth[i]),len(lpred[i]))) == 0):\n",
        "      damdist.append(0)\n",
        "  else:\n",
        "      dist = damerau.distance(ltruth[i], lpred[i])/(max(len(ltruth[i]),len(lpred[i])))\n",
        "      damdist.append(dist)\n",
        "  \n",
        "  \n",
        "print(\"The DLS value for suffix is :\"+str(100-sum(damdist)/len(damdist)*100))\n",
        "# damdist"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The DLS value for suffix is :22.7961432506887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOZmetfO4URY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}